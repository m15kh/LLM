{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3028ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from pprint import pprint\n",
    "from SmartAITool.core import bprint\n",
    "# Load API configuration from a YAML file\n",
    "with open(\"/home/rteam2/m15kh/LLM/config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = config.get(\"LANGSMITH_TRACING\", \"false\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = config[\"LANGSMITH_API_KEY\"]\n",
    "os.environ[\"TAVILY_API_KEY\"] = config[\"TAVILY_API_KEY\"]\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = config['HUGGINGFACEHUB_API_TOKEN']\n",
    "GPT_API_KEY = config['GPT_API_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9e5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\n",
    "    api_key= GPT_API_KEY,\n",
    "    base_url=\"https://api.gilas.io/v1/\",\n",
    "    model=\"gpt-4o-mini\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10d42f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    api_key= GPT_API_KEY,\n",
    "    base_url=\"https://api.gilas.io/v1/\",\n",
    "    model=\"text-embedding-3-large\", dimensions=3072 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf965ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x74dcfc13b8f0>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "print((vector_store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b1a237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43130\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939faea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b667c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c2c0d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
      " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 971}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
      " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.')]\n"
     ]
    }
   ],
   "source": [
    "pprint(all_splits[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f807c783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0: 207 tokens\n",
      "Split 1: 110 tokens\n",
      "Split 2: 123 tokens\n",
      "Split 3: 146 tokens\n",
      "Split 4: 196 tokens\n",
      "Split 5: 105 tokens\n",
      "Split 6: 194 tokens\n",
      "Split 7: 140 tokens\n",
      "Split 8: 45 tokens\n",
      "Split 9: 266 tokens\n",
      "Split 10: 82 tokens\n",
      "Split 11: 184 tokens\n",
      "Split 12: 178 tokens\n",
      "Split 13: 108 tokens\n",
      "Split 14: 213 tokens\n",
      "Split 15: 200 tokens\n",
      "Split 16: 91 tokens\n",
      "Split 17: 100 tokens\n",
      "Split 18: 157 tokens\n",
      "Split 19: 164 tokens\n",
      "Split 20: 173 tokens\n",
      "Split 21: 94 tokens\n",
      "Split 22: 150 tokens\n",
      "Split 23: 175 tokens\n",
      "Split 24: 102 tokens\n",
      "Split 25: 93 tokens\n",
      "Split 26: 194 tokens\n",
      "Split 27: 170 tokens\n",
      "Split 28: 128 tokens\n",
      "Split 29: 91 tokens\n",
      "Split 30: 130 tokens\n",
      "Split 31: 145 tokens\n",
      "Split 32: 139 tokens\n",
      "Split 33: 148 tokens\n",
      "Split 34: 187 tokens\n",
      "Split 35: 34 tokens\n",
      "Split 36: 200 tokens\n",
      "Split 37: 157 tokens\n",
      "Split 38: 120 tokens\n",
      "Split 39: 202 tokens\n",
      "Split 40: 128 tokens\n",
      "Split 41: 284 tokens\n",
      "Split 42: 197 tokens\n",
      "Split 43: 116 tokens\n",
      "Split 44: 225 tokens\n",
      "Split 45: 159 tokens\n",
      "Split 46: 164 tokens\n",
      "Split 47: 217 tokens\n",
      "Split 48: 24 tokens\n",
      "Split 49: 197 tokens\n",
      "Split 50: 190 tokens\n",
      "Split 51: 55 tokens\n",
      "Split 52: 4 tokens\n",
      "Split 53: 15 tokens\n",
      "Split 54: 221 tokens\n",
      "Split 55: 208 tokens\n",
      "Split 56: 95 tokens\n",
      "Split 57: 153 tokens\n",
      "Split 58: 213 tokens\n",
      "Split 59: 76 tokens\n",
      "Split 60: 28 tokens\n",
      "Split 61: 137 tokens\n",
      "Split 62: 126 tokens\n",
      "Split 63: 320 tokens\n",
      "Split 64: 306 tokens\n",
      "Split 65: 315 tokens\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "for i, split in enumerate(all_splits):\n",
    "    num_tokens = len(encoding.encode(split.page_content))\n",
    "    print(f\"Split {i}: {num_tokens} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7df5577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safely embed in batches of 1 to avoid exceeding total token limit per request\n",
    "document_ids = []\n",
    "\n",
    "for split in all_splits:\n",
    "    ids = vector_store.add_documents(documents=[split])\n",
    "    document_ids.extend(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a6d0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b40940bf-b572-4a16-a270-ba6d89080dfb', 'd2e288ba-3cd3-416e-8a0b-9f0be004a041', '159730dd-135e-445c-8ed4-261e3a7e8df2']\n"
     ]
    }
   ],
   "source": [
    "print(document_ids[:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "363a7b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3091ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "    \n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d089e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c5129cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cf1ed5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='159730dd-135e-445c-8ed4-261e3a7e8df2', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='ee4e24a8-d37c-4135-b68f-c8daa863d897', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='a892090e-f079-405e-aa4e-d463affac455', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17803}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'), Document(id='531c54d9-1595-40ec-b813-d8624f05819d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17413}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:')]\n",
      "\n",
      "\n",
      "Answer: Task decomposition is the process of breaking down a complex task into smaller, more manageable steps to enhance execution and understanding. This can be achieved through techniques like Chain of Thought (CoT), which encourages models to think step by step, or the Tree of Thoughts method, which explores multiple reasoning paths. Essentially, it allows for clearer planning and execution in tasks that would otherwise be too complicated to handle in one go.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "583b93d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='159730dd-135e-445c-8ed4-261e3a7e8df2', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='ee4e24a8-d37c-4135-b68f-c8daa863d897', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='a892090e-f079-405e-aa4e-d463affac455', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17803}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'), Document(id='531c54d9-1595-40ec-b813-d8624f05819d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17413}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Task decomposition is the process of breaking down a complex task into smaller, more manageable steps. This can involve techniques such as chain of thought (CoT), where a model is prompted to think step-by-step, or the Tree of Thoughts approach, which explores multiple reasoning possibilities at each step. The method can utilize simple prompts, task-specific instructions, or human inputs to effectively structure the tasks.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b81af180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Task| decomposition| is| the| process| of| breaking| down| a| complex| task| into| smaller|,| manageable| steps|.| This| involves| utilizing| techniques| like| Chain| of| Thought| (|Co|T|)| to| guide| models| in| reasoning| step| by| step|,| thereby| simplifying| the| overall| task|.| It| can| be| executed| through| simple| prompts|,| task|-specific| instructions|,| or| human| inputs|.|||"
     ]
    }
   ],
   "source": [
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c98ae072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
